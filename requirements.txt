# invoke this by running: pip install -r requirements.txt

# Needed to use ollama as the inference server
ollama
